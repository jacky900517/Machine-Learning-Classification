OutputVideo:
https://youtu.be/qisugaQHFy0?si=u9HcOoyu_Hvzujn5
https://youtu.be/W5oskQJW7vY?si=qcxJz2MtuV94gQ3e

────────────────
期中報告：基於 OpenCV 的車道線偵測演算法迭代與實現

  1.	前言

1.1 動機與目的

本專案的目標是在 Raspberry Pi 5 上建立一套即時車道線偵測系統。整個系統的工作方式是由前方攝影機取得道路畫面，並透過電腦視覺演算法辨識車道線，讓車輛能判斷自己目前是否位於車道內，並保持在車道內穩定往前行駛。此功能是實現基本自動駕駛輔助與自主導航的必要條件。

1.2 挑戰

在真實道路情境下，車道線偵測會遇到許多困難，包括：
	•	光線變化（陰影、強光等）
	•	路面標線磨損或被遮擋
	•	虛線（不連續線段）偵測不穩定
	•	道路拓寬、匝道匯入或匝道匯出時，會同時出現多組線條造成干擾
	•	彎道偵測
	•	在 Raspberry Pi 5 上必須即時運算的效能限制

本報告聚焦於兩個主要問題的處理方式，也就是「虛線不穩定」以及「匝道干擾」，並說明我們如何在不依賴複雜校準流程的前提下，逐步改善演算法。
	
  2.	演算法迭代歷程

整體開發是使用 OpenCV，基於傳統電腦視覺的方法來進行。這樣做的原因是這類方法的運算量相對可控，理論上比較容易在 Raspberry Pi 上達到即時效果。整個開發過程是一個不斷嘗試、觀察失敗原因、再調整的迭代流程。

2.1 初始方法：基本霍夫變換 (Hough Transform)

流程大致為：將影像轉成灰階，做高斯模糊，之後用 Canny 邊緣偵測找出邊界，再用機率式霍夫直線變換 (HoughLinesP) 去找線段，最後將偵測到的線條進行某種平均或平滑。

遇到的問題如下：

(1) 彎道問題：HoughLinesP 擅長找直線，但彎道不是直線，所以在彎道處表現不佳。

(2) 匝道問題：當路面同時出現主車道線和匝道線（例如影片 LaneVideo.mp4 在時間 00:17 左右），HoughLinesP 會同時找出兩組不同方向的線。後續如果只是把線條做平均，得到的「代表車道線」會嚴重偏掉，甚至往匝道方向跑。

(3) 虛線問題：虛線並不是連續的，HoughLinesP 常常把它切成很多短線段，甚至直接偵測不到某些區段。於是斜率、截距等參數會在幀與幀之間劇烈跳動，造成輸出結果非常不穩定。

2.2 探索並捨棄的方法：鳥瞰圖加像素追蹤

在這個階段我們嘗試了另一個典型的車道線偵測架構。做法是先做透視變換，把路面轉成接近俯視角度的鳥瞰圖，接著用顏色或梯度閾值把車道線像素抓出來，再用滑動視窗從下往上追蹤這些像素，最後用多項式去擬合出左右車道線。

這種做法的優點在於：
	•	根據LaneVideo.mp4的場景可以做到十分完美的效果，偵測在遇到閘道時也能即時的修正
	•	不依賴 HoughLinesP 找直線，而是直接在像素層級追蹤，因此對虛線比較穩定。
	•	彎道也能被平滑地擬合成曲線，而不是強迫當成直線。
	•	透過滑動視窗的追蹤邏輯，可以忽略與主車道無關的雜訊線條。

但最後放棄這條路，原因是：這套方法非常仰賴一組準確的透視變換參數，也就是攝影機畫面中四個點的座標（src_pts）。這些點必須手動標定。只要相機角度改變（高度、俯角、水平旋轉），就必須重新標定。雖然有嘗試用 HoughLinesP 推估消失點、再自動推回透視變換參數，但結果不穩定。
雖然可以完美解決當下LaneVideo.mp4中的場景，但因為我的目標是「不需要手動校準就能跑」，在所有場景都要可以直接使用，所以這條路線被暫時捨棄，未來在自走車上相機位置如果都是固定的，行駛場景也都是固定的話也會考慮重新使用鳥瞰的方式。

2.3 回到 Hough 後的改進嘗試（聚焦在追蹤與決策）

因為鳥瞰圖法不符合我們「免手動校準」的需求，我們回到 Hough-based 的做法。但這次不再只是單純地拿到線就平均，而是開始圍繞「怎麼選對線」和「怎麼在時間上保持穩定」來下功夫。主要嘗試包含：

(a) 加入時間平滑與記憶：
我們引入 smoothing_factor 和 last_good_params 等記憶機制。簡單說，就是把上一幀的結果拿來平滑當前的線，讓輸出不要每幀跳太大。同時，如果這一幀偵測失敗，我們會用上一幀的可靠結果暫時頂著，這個行為可以稱為 coasting。

(b) 鎖定追蹤（位置優先）：
嘗試一直鎖住上一幀附近的線段，假設真實的車道線應該跟上一幀的位置差不會太遠。這個策略最後失敗，因為一旦在匝道處鎖到錯誤的那條線，它會一直維持鎖定，沒有機制把它拉回主車道。

(c) 基於預測的策略（寬度與斜率）：
我們嘗試用預期應該出現的左右車道線距離（左右線之間的寬度），或斜率範圍去過濾不合理的線段。但這在虛線區很脆弱，因為原始 Hough 給的斜率和位置就已經很不穩，導致誤判，還可能把錯誤資料寫進記憶裡，越矯正越歪。

(d) 線對追蹤與混合評分：
我們開始同時看「一組左線 + 一組右線」的配對，而不是單看個別線條。對每一對線，我們計算它們在影像底部的寬度（左右線距離）和中心點位置（兩線中點在畫面底部的 x 座標）。然後我們用這些數值去打分，嘗試挑出最合理的那一對。這個方法已經有進步，但仍然會受到 Hough 資料品質的限制，如果 Hough 在那一幀給的線段本身就不乾淨，評分也沒救。

(e) 訊號濾波器：
這一步是關鍵突破，來自我觀察到輸出結果後的想法。

做法是：在我們對線對進行評分之前，先把那些明顯「不值得參考」的線段直接丟掉。我們會檢查每條候選線段的兩個特性：
(1) 它的位置是不是偏離了預測位置很多。
(2) 它是不是一條很短、很弱的線（通常代表雜訊或只是一小段虛線）。

如果一條線「同時」滿足「位置超出合理範圍」又「線很短」，那就直接忽略，不拿進後面的評分流程。

這個機制在匝道處特別有效。因為匝道線一開始往往只佔畫面一小角落，線段很短，位置也很偏，這種線就會被濾掉。於是評分階段就比較不會被它們干擾。另一方面，如果匝道邊線已經變成非常長的一整條實線，那它雖然位置偏，但因為「很長」，它會被保留下來，交由後面的評分系統再判斷是否要採用。換句話說，這個濾波器不會太激進到什麼都刪，
而是刪「又偏又弱」的雜訊訊號。這就是這個版本可以在匝道場景下表現明顯更好的主因。

2.4 在「訊號濾波器」基礎上做的穩定性強化

雖然明顯改善了匝道時的表現，但虛線的跳動仍然存在。我們嘗試過下列方法：
	•	冷卻機制：當畫面剛從異常中恢復時，暫時降低對異常的敏感度，避免馬上又被 Hough 的抖動嚇到。
	•	強平滑：把 smoothing_factor 調得更強，讓輸出更穩定，不過副作用是反應變慢。
	•	左側位置懲罰：對明顯往左飄的一側給額外扣分，降低跳來跳去的情況。



	3.	當前版本的演算法流程說明

以下是 LaneDetection.py（對應到影片 LaneVideo.mp4 / LaneVideo2.mp4）整體的主要步驟，依照實際程式邏輯描述：

(1) 影像輸入與預處理：
每一幀影像先做 Canny 邊緣偵測，再套用一個梯形區域的遮罩 (ROI)，只保留道路區域的邊緣，減少雜訊。

(2) 直線段偵測：
在遮罩後的邊緣影像上使用 cv2.HoughLinesP，取得所有可能屬於車道線的直線段。

(3) 線段分類與參數化：
對每條線段計算它的斜率和截距，並依照斜率的方向把它分成左邊候選或右邊候選。同時保留原始線段座標，之後可以計算線段長度。

(4) 訊號濾波階段：
我們先根據上一幀平滑後的結果，推估此幀左右車道線在影像底部應該出現的位置。然後對每一條候選線段，計算兩件事：
	•	該線段在畫面底部的 x 位置與預測位置差多少。
	•	該線段的實際長度。

如果一條線同時「離預測位置很遠」而且「又很短」，就把它忽略，不讓它進入後續配對流程。剩下通過檢查的候選線段，才是有效樣本。

(5) 線對評估與選擇：
把所有通過濾波的左線與右線配對，形成成對的「車道假說」。對每一對，我們計算：
	•	這對線在畫面底部的寬度（兩線的水平距離）。
	•	這對線在畫面底部的中心點位置（兩線中間點的 x 值）。

在起始的校準階段，我們優先選擇「跨過影像中心且寬度合理」的組合，用來建立基準的平均寬度與平均中心點。校準結束後，我們就使用一個打分系統：比較此幀線對的寬度與中心點，和歷史上記錄的平均值差多少，差越小分數越好，最後挑出分數最好的那一對作為當前幀候選（best_pair_overall）。

(6) 異常偵測與恢復：
我們會檢查 best_pair_overall 是否突然和基準差很多（例如中心點整個往匝道方向飄走，或寬度突然變超大）。如果差異過大，代表可能進入異常狀態。進入異常狀態後，我們會再檢查其他線對裡面有沒有「看起來比較合理」的組合。如果找到，就用那一組並視為已經恢復正常。如果找不到，就暫時接受現在這個偏掉的結果，但標記仍在異常狀態。

(7) Coasting（暫時沿用上一幀）：
如果在濾波後，根本沒有成對的有效線（例如右線整個不見），或是雖然進入異常狀態但仍然沒有可靠的備案，系統就啟動 coasting。也就是用上一幀最後確認過「是好的」的線條參數來畫，避免畫面整個消失或瘋狂亂跳。

(8) 時間平滑與記憶更新：
確定了這一幀要使用的左右線之後，會用指數平滑的方式（根據 smoothing_factor）把它和上一幀的平滑結果結合。平滑後的參數會存回記憶中，當成下一幀的預測依據。只有在不屬於異常狀態時，才會更新「基準寬度、基準中心點」和「最後良好線條參數」，以免錯誤狀態污染記憶。

(9) 座標轉換與繪製：
將平滑後的線條參數轉換成實際畫在畫面上的兩條邊界線，並在它們之間填上一塊半透明的綠色區域，代表「目前推定的行駛車道區域」。

(10) 影像輸出：
將畫好車道區域的畫面寫入輸出影片檔案，作為本幀的最終結果。
	4.	當前版本的優點與缺點

優點：
	•	在測試影片 LaneVideo.mp4 中，當遇到匝道匯出時，系統能夠排除大部分由匝道產生的假線條干擾，並且之後能回到主車道。
	•	不需要手動進行透視變換的校準，較能適應不同攝影機角度（相較於固定鳥瞰圖方法）。
	•	加入了平滑、異常狀態判定、coasting 等機制，比起最原始的 Hough 直線平均法穩定許多。
  • 在第二個測試影片 LaneVideo2.mp4 中也展示出了很好的效果，前幾個版本的算法中，我們在影片中0:14秒處出現的隔壁車道白色汽車，原本是會把偵測範圍帶走的，但是這個版本有了濾波器跟冷卻機制後，我們的偵測就不會受到污染。
  • 還有就是在第二個測試影片中的場景，進出隧道時的明顯光線變化，在原本是很容易導致我們偵測範圍失真的，在最終的版本我們克服問題，不再受影響。

缺點：
	•	整體仍然依賴 HoughLinesP。Hough 在偵測虛線時的品質不穩，會直接影響整個系統的上限，效果會不如鳥瞰圖的方式好。
	•	在虛線區域仍會發生左右邊界短暫跳動或被拉扯的情形，特別是當虛線本身偵測得不好時。
	•	系統中有許多參數（濾波長度閾值、位置允許範圍、線對評分權重、異常判定閾值、平滑係數等），可能需要依照光線、路面材質、攝影機裝法等重新調整。
	•	相比最簡單的版本，這套作法計算量更高（要做線對組合評分、狀態判定等），必須在 Raspberry Pi 5 上實測它的即時效能。

	5.	結論與未來工作

目前的版本代表我們在不做人工校準的前提下，針對「虛線不穩定」和「匝道干擾」這兩個最大痛點，所能達到的最佳折衷。訊號濾波器的核心概念，是在評分和決策之前，先刪掉「又偏又弱」的線段，藉此降低雜訊，並避免在匝道情境下被拉走。

接下來可以考慮的方向如下：

(1) 參數微調：
在實際部署到 Raspberry Pi 5 與實際道路（或測試跑道）時，根據實測畫面與鏡頭安裝位置，重新微調各種閾值與平滑係數，讓穩定性與反應速度之間達到更好平衡。

(2) 嘗試不依賴 Hough 的路徑（如果效能允許）：
研究是否能在原始視角下，直接對像素做聚類、輪廓分析或其他方法，來取代 HoughLinesP 對單條直線的依賴，特別針對虛線。

(3) 重新評估鳥瞰圖流程（如果需要極高穩定度）：
如果未來自走車的攝影機固定安裝在一個不會再動的位置，那麼重新回到「鳥瞰圖＋滑動視窗」的策略其實是可行的。只要允許做一次性手動標定，它可能會帶來整體上更平滑、更抗干擾的結果，特別是在長期行駛、彎道和匝道場景中。

────────────────
